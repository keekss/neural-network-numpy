{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Demo"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data loading\n",
        "\n",
        "### Example dataset: Fashion MNIST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "download_and_save_files(), line 25 (2024-02-12 @ 01:18:51)\n",
            "-> [INFO] File train-images-idx3-ubyte.gz already exists in ./data/\n",
            "\n",
            "download_and_save_files(), line 25 (2024-02-12 @ 01:18:51)\n",
            "-> [INFO] File train-labels-idx1-ubyte.gz already exists in ./data/\n",
            "\n",
            "download_and_save_files(), line 25 (2024-02-12 @ 01:18:51)\n",
            "-> [INFO] File t10k-images-idx3-ubyte.gz already exists in ./data/\n",
            "\n",
            "download_and_save_files(), line 25 (2024-02-12 @ 01:18:51)\n",
            "-> [INFO] File t10k-labels-idx1-ubyte.gz already exists in ./data/\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1400x600 with 10 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from scripts.load_sample_data import prepare_and_load_fashion_mnist_data\n",
        "\n",
        "data = prepare_and_load_fashion_mnist_data()\n",
        "\n",
        "train_images = data['train_images']\n",
        "train_labels = data['train_labels']\n",
        "test_images = data['test_images']\n",
        "test_labels = data['test_labels']"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Custom dataset\n",
        "\n",
        "The model can train on any dataset; however, the following requirements must be met:\n",
        "\n",
        "* TODO\n",
        "* "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training with default parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Hyperparameter tuning\n",
        "\n",
        "[Hyperopt](https://github.com/hyperopt/hyperopt) optimizes hyperparameters within a search space based on previous trials.\n",
        "\n",
        "Here, the [Tree Parzen Estimator](chrome-extension://efaidnbmnnnibpcajpcglclefindmkaj/https://proceedings.neurips.cc/paper/2011/file/86e8f7ab32cfd12577bc2619bc635690-Paper.pdf) uses [Bayesian principles](https://towardsdatascience.com/a-conceptual-explanation-of-bayesian-model-based-hyperparameter-optimization-for-machine-learning-b8172278050f#:~:text=The%20Tree%20Parzen%20Estimator%20is,will%20explore%20in%20further%20articles.) to adjust hyperparameters between calls to `NeuralNetwork.fit`.\n",
        "\n",
        "The search space includes initialization and training parameters.\n",
        "\n",
        "Referenced [hyperopt article](https://towardsdatascience.com/optimise-your-hyperparameter-tuning-with-hyperopt-861573239eb5)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best 5 models:                                        \n",
            "  0%|          | 0/50 [00:16<?, ?trial/s, best loss=?]"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>min_loss_val</th>\n",
              "      <th>max_acc_val</th>\n",
              "      <th>h_layers</th>\n",
              "      <th>heights</th>\n",
              "      <th>lr</th>\n",
              "      <th>batch_size</th>\n",
              "      <th>keep_rates</th>\n",
              "      <th>reshuff</th>\n",
              "      <th>max_strikes</th>\n",
              "      <th>max_consec</th>\n",
              "      <th>epochs_min_loss_val</th>\n",
              "      <th>total_sec</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1.553061e+18</th>\n",
              "      <td>0.296820</td>\n",
              "      <td>0.8948</td>\n",
              "      <td>3</td>\n",
              "      <td>flat, (1868 =&gt; 1868)</td>\n",
              "      <td>0.000727</td>\n",
              "      <td>1680</td>\n",
              "      <td>range: (0.9355129444418089, 1)</td>\n",
              "      <td>True</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>411.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6.378536e+17</th>\n",
              "      <td>0.299361</td>\n",
              "      <td>0.8958</td>\n",
              "      <td>2</td>\n",
              "      <td>flat, (2147 =&gt; 2147)</td>\n",
              "      <td>0.000739</td>\n",
              "      <td>2509</td>\n",
              "      <td>range: (0.9732144341134844, 1)</td>\n",
              "      <td>False</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>14</td>\n",
              "      <td>484.84</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1.183797e+18</th>\n",
              "      <td>0.300882</td>\n",
              "      <td>0.8928</td>\n",
              "      <td>2</td>\n",
              "      <td>expanding, (860 =&gt; 1318)</td>\n",
              "      <td>0.000766</td>\n",
              "      <td>1039</td>\n",
              "      <td>range: (0.9963679433526818, 1)</td>\n",
              "      <td>False</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>119.59</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2.192788e+18</th>\n",
              "      <td>0.302602</td>\n",
              "      <td>0.8945</td>\n",
              "      <td>2</td>\n",
              "      <td>contracting, (2382 =&gt; 1427)</td>\n",
              "      <td>0.000892</td>\n",
              "      <td>979</td>\n",
              "      <td>range: (0.9219362813698884, 1)</td>\n",
              "      <td>True</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>294.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1.362338e+18</th>\n",
              "      <td>0.304246</td>\n",
              "      <td>0.8927</td>\n",
              "      <td>2</td>\n",
              "      <td>contracting, (2372 =&gt; 2212)</td>\n",
              "      <td>0.000549</td>\n",
              "      <td>3193</td>\n",
              "      <td>range: (0.9998225539494774, 1)</td>\n",
              "      <td>False</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>12</td>\n",
              "      <td>463.07</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              min_loss_val  max_acc_val  h_layers  \\\n",
              "1.553061e+18      0.296820       0.8948         3   \n",
              "6.378536e+17      0.299361       0.8958         2   \n",
              "1.183797e+18      0.300882       0.8928         2   \n",
              "2.192788e+18      0.302602       0.8945         2   \n",
              "1.362338e+18      0.304246       0.8927         2   \n",
              "\n",
              "                                  heights        lr  batch_size  \\\n",
              "1.553061e+18         flat, (1868 => 1868)  0.000727        1680   \n",
              "6.378536e+17         flat, (2147 => 2147)  0.000739        2509   \n",
              "1.183797e+18     expanding, (860 => 1318)  0.000766        1039   \n",
              "2.192788e+18  contracting, (2382 => 1427)  0.000892         979   \n",
              "1.362338e+18  contracting, (2372 => 2212)  0.000549        3193   \n",
              "\n",
              "                                  keep_rates  reshuff  max_strikes  \\\n",
              "1.553061e+18  range: (0.9355129444418089, 1)     True            2   \n",
              "6.378536e+17  range: (0.9732144341134844, 1)    False            2   \n",
              "1.183797e+18  range: (0.9963679433526818, 1)    False            2   \n",
              "2.192788e+18  range: (0.9219362813698884, 1)     True            2   \n",
              "1.362338e+18  range: (0.9998225539494774, 1)    False            2   \n",
              "\n",
              "              max_consec  epochs_min_loss_val  total_sec  \n",
              "1.553061e+18           2                    9     411.99  \n",
              "6.378536e+17           2                   14     484.84  \n",
              "1.183797e+18           2                    8     119.59  \n",
              "2.192788e+18           2                    9     294.02  \n",
              "1.362338e+18           2                   12     463.07  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Most recent 5 models:                                 \n",
            "  0%|          | 0/50 [00:16<?, ?trial/s, best loss=?]"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>min_loss_val</th>\n",
              "      <th>max_acc_val</th>\n",
              "      <th>h_layers</th>\n",
              "      <th>heights</th>\n",
              "      <th>lr</th>\n",
              "      <th>batch_size</th>\n",
              "      <th>keep_rates</th>\n",
              "      <th>reshuff</th>\n",
              "      <th>max_strikes</th>\n",
              "      <th>max_consec</th>\n",
              "      <th>epochs_min_loss_val</th>\n",
              "      <th>total_sec</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2.228268e+18</th>\n",
              "      <td>0.309001</td>\n",
              "      <td>0.8903</td>\n",
              "      <td>4</td>\n",
              "      <td>flat, (1257 =&gt; 1257)</td>\n",
              "      <td>0.000712</td>\n",
              "      <td>2202</td>\n",
              "      <td>range: (0.9818383588286673, 1)</td>\n",
              "      <td>True</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>355.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8.511880e+17</th>\n",
              "      <td>0.309278</td>\n",
              "      <td>0.8893</td>\n",
              "      <td>2</td>\n",
              "      <td>flat, (2277 =&gt; 2277)</td>\n",
              "      <td>0.000578</td>\n",
              "      <td>2521</td>\n",
              "      <td>range: (0.9730401212750497, 1)</td>\n",
              "      <td>False</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>412.29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1.067276e+18</th>\n",
              "      <td>0.347681</td>\n",
              "      <td>0.8757</td>\n",
              "      <td>1</td>\n",
              "      <td>expanding, (1268 =&gt; 1692)</td>\n",
              "      <td>0.000986</td>\n",
              "      <td>4554</td>\n",
              "      <td>range: (0.9506594907788668, 1)</td>\n",
              "      <td>True</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>13</td>\n",
              "      <td>113.61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1.367086e+18</th>\n",
              "      <td>0.317464</td>\n",
              "      <td>0.8869</td>\n",
              "      <td>2</td>\n",
              "      <td>flat, (1514 =&gt; 1514)</td>\n",
              "      <td>0.000735</td>\n",
              "      <td>1807</td>\n",
              "      <td>range: (0.965780371799544, 1)</td>\n",
              "      <td>False</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>213.41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2.254605e+18</th>\n",
              "      <td>0.314946</td>\n",
              "      <td>0.8889</td>\n",
              "      <td>3</td>\n",
              "      <td>expanding, (945 =&gt; 1032)</td>\n",
              "      <td>0.000372</td>\n",
              "      <td>968</td>\n",
              "      <td>range: (0.990171437679217, 1)</td>\n",
              "      <td>False</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>191.71</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              min_loss_val  max_acc_val  h_layers                    heights  \\\n",
              "2.228268e+18      0.309001       0.8903         4       flat, (1257 => 1257)   \n",
              "8.511880e+17      0.309278       0.8893         2       flat, (2277 => 2277)   \n",
              "1.067276e+18      0.347681       0.8757         1  expanding, (1268 => 1692)   \n",
              "1.367086e+18      0.317464       0.8869         2       flat, (1514 => 1514)   \n",
              "2.254605e+18      0.314946       0.8889         3   expanding, (945 => 1032)   \n",
              "\n",
              "                    lr  batch_size                      keep_rates  reshuff  \\\n",
              "2.228268e+18  0.000712        2202  range: (0.9818383588286673, 1)     True   \n",
              "8.511880e+17  0.000578        2521  range: (0.9730401212750497, 1)    False   \n",
              "1.067276e+18  0.000986        4554  range: (0.9506594907788668, 1)     True   \n",
              "1.367086e+18  0.000735        1807   range: (0.965780371799544, 1)    False   \n",
              "2.254605e+18  0.000372         968   range: (0.990171437679217, 1)    False   \n",
              "\n",
              "              max_strikes  max_consec  epochs_min_loss_val  total_sec  \n",
              "2.228268e+18            2           2                    7     355.92  \n",
              "8.511880e+17            2           2                    9     412.29  \n",
              "1.067276e+18            2           2                   13     113.61  \n",
              "1.367086e+18            2           2                    9     213.41  \n",
              "2.254605e+18            2           2                    8     191.71  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training w/ hyperparams:                              \n",
            "  0%|          | 0/50 [00:16<?, ?trial/s, best loss=?]"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>h_layers</th>\n",
              "      <th>heights</th>\n",
              "      <th>lr</th>\n",
              "      <th>batch_size</th>\n",
              "      <th>keep_rates</th>\n",
              "      <th>reshuff</th>\n",
              "      <th>max_strikes</th>\n",
              "      <th>max_consec</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <td>3</td>\n",
              "      <td>flat, (2064 =&gt; 2064)</td>\n",
              "      <td>0.000237</td>\n",
              "      <td>60</td>\n",
              "      <td>range: (0.9837143956637605, 1)</td>\n",
              "      <td>True</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  h_layers               heights        lr  batch_size  \\\n",
              "         3  flat, (2064 => 2064)  0.000237          60   \n",
              "\n",
              "                      keep_rates  reshuff  max_strikes  max_consec  \n",
              "  range: (0.9837143956637605, 1)     True            2           2  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total strikes:    0/2                                 \n",
            "Consec strikes:   0/2                                 \n",
            "Performance By Epoch:                                 \n",
            "  0%|          | 0/50 [00:16<?, ?trial/s, best loss=?]"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss_train</th>\n",
              "      <th>loss_val</th>\n",
              "      <th>acc_train</th>\n",
              "      <th>acc_val</th>\n",
              "      <th>total_sec_elapsed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4.565998</td>\n",
              "      <td>4.566477</td>\n",
              "      <td>0.048067</td>\n",
              "      <td>0.0452</td>\n",
              "      <td>15.75</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   loss_train  loss_val  acc_train  acc_val  total_sec_elapsed\n",
              "0    4.565998  4.566477   0.048067   0.0452              15.75"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Weight Percentiles after Epoch 0:                     \n",
            "Percentiles formatted as \"(Range: Min => Max)\"        \n",
            "  0%|          | 0/50 [00:16<?, ?trial/s, best loss=?]"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_efdbf_row0_col0, #T_efdbf_row0_col1, #T_efdbf_row0_col2, #T_efdbf_row0_col3, #T_efdbf_row1_col0, #T_efdbf_row1_col1, #T_efdbf_row1_col2, #T_efdbf_row1_col3, #T_efdbf_row2_col0, #T_efdbf_row2_col1, #T_efdbf_row2_col2, #T_efdbf_row2_col3, #T_efdbf_row3_col0, #T_efdbf_row3_col1, #T_efdbf_row3_col2, #T_efdbf_row3_col3 {\n",
              "  white-space: pre;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_efdbf\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_efdbf_level0_col0\" class=\"col_heading level0 col0\" >all</th>\n",
              "      <th id=\"T_efdbf_level0_col1\" class=\"col_heading level0 col1\" >99p</th>\n",
              "      <th id=\"T_efdbf_level0_col2\" class=\"col_heading level0 col2\" >95p</th>\n",
              "      <th id=\"T_efdbf_level0_col3\" class=\"col_heading level0 col3\" >50p</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_efdbf_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "      <td id=\"T_efdbf_row0_col0\" class=\"data row0 col0\" >(0.4993  : -0.2367  =>   0.2626)</td>\n",
              "      <td id=\"T_efdbf_row0_col1\" class=\"data row0 col1\" >(0.2602  : -0.1301  =>   0.1302)</td>\n",
              "      <td id=\"T_efdbf_row0_col2\" class=\"data row0 col2\" >(0.1979  : -0.0989  =>   0.0990)</td>\n",
              "      <td id=\"T_efdbf_row0_col3\" class=\"data row0 col3\" >(0.0682  : -0.0341  =>   0.0341)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_efdbf_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "      <td id=\"T_efdbf_row1_col0\" class=\"data row1 col0\" >(0.5243  : -0.2549  =>   0.2693)</td>\n",
              "      <td id=\"T_efdbf_row1_col1\" class=\"data row1 col1\" >(0.2602  : -0.1301  =>   0.1300)</td>\n",
              "      <td id=\"T_efdbf_row1_col2\" class=\"data row1 col2\" >(0.1978  : -0.0989  =>   0.0989)</td>\n",
              "      <td id=\"T_efdbf_row1_col3\" class=\"data row1 col3\" >(0.0681  : -0.0340  =>   0.0341)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_efdbf_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "      <td id=\"T_efdbf_row2_col0\" class=\"data row2 col0\" >(0.5086  : -0.2473  =>   0.2613)</td>\n",
              "      <td id=\"T_efdbf_row2_col1\" class=\"data row2 col1\" >(0.2601  : -0.1300  =>   0.1301)</td>\n",
              "      <td id=\"T_efdbf_row2_col2\" class=\"data row2 col2\" >(0.1981  : -0.0990  =>   0.0991)</td>\n",
              "      <td id=\"T_efdbf_row2_col3\" class=\"data row2 col3\" >(0.0681  : -0.0341  =>   0.0340)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_efdbf_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "      <td id=\"T_efdbf_row3_col0\" class=\"data row3 col0\" >(0.3986  : -0.2097  =>   0.1889)</td>\n",
              "      <td id=\"T_efdbf_row3_col1\" class=\"data row3 col1\" >(0.2610  : -0.1309  =>   0.1301)</td>\n",
              "      <td id=\"T_efdbf_row3_col2\" class=\"data row3 col2\" >(0.2003  : -0.1009  =>   0.0994)</td>\n",
              "      <td id=\"T_efdbf_row3_col3\" class=\"data row3 col3\" >(0.0675  : -0.0338  =>   0.0337)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7fb250c39fd0>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training epoch 1:                                     \n",
            "  0%|          | 0/50 [00:16<?, ?trial/s, best loss=?]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/1000 [00:00<?, ?it/s]\n",
            "  0%|          | 1/1000 [00:00<03:18,  5.04it/s]\n",
            "  0%|          | 2/1000 [00:00<02:22,  7.00it/s]\n",
            "  0%|          | 4/1000 [00:00<01:49,  9.06it/s]\n",
            "  0%|          | 5/1000 [00:00<01:47,  9.28it/s]\n",
            "  1%|          | 7/1000 [00:00<01:41,  9.78it/s]\n",
            "  1%|          | 9/1000 [00:00<01:38, 10.05it/s]\n",
            "  1%|1         | 11/1000 [00:01<01:37, 10.12it/s]\n",
            "  1%|1         | 13/1000 [00:01<01:38, 10.00it/s]\n",
            "  1%|1         | 14/1000 [00:01<01:39,  9.94it/s]\n",
            "  2%|1         | 15/1000 [00:01<01:39,  9.89it/s]\n",
            "  2%|1         | 16/1000 [00:01<01:39,  9.88it/s]\n",
            "  2%|1         | 17/1000 [00:01<01:39,  9.90it/s]\n",
            "  2%|1         | 18/1000 [00:01<01:39,  9.89it/s]\n",
            "  2%|1         | 19/1000 [00:01<01:39,  9.84it/s]\n",
            "  2%|2         | 20/1000 [00:02<01:41,  9.62it/s]\n",
            "  2%|2         | 21/1000 [00:02<01:42,  9.56it/s]\n",
            "  2%|2         | 22/1000 [00:02<01:41,  9.68it/s]\n",
            "  2%|2         | 23/1000 [00:02<01:42,  9.58it/s]\n",
            "  2%|2         | 24/1000 [00:02<01:41,  9.61it/s]\n",
            "  2%|2         | 25/1000 [00:02<01:40,  9.71it/s]\n",
            "  3%|2         | 26/1000 [00:02<01:40,  9.69it/s]\n",
            "  3%|2         | 28/1000 [00:02<01:38,  9.91it/s]\n",
            "  3%|2         | 29/1000 [00:03<01:38,  9.87it/s]\n",
            "  3%|3         | 30/1000 [00:03<01:38,  9.88it/s]\n",
            "  3%|3         | 31/1000 [00:03<01:38,  9.83it/s]\n",
            "  3%|3         | 32/1000 [00:03<01:41,  9.58it/s]\n",
            "  3%|3         | 33/1000 [00:03<01:40,  9.65it/s]\n",
            "  4%|3         | 35/1000 [00:03<01:38,  9.79it/s]\n",
            "  4%|3         | 36/1000 [00:03<01:39,  9.68it/s]\n",
            "  4%|3         | 37/1000 [00:03<01:39,  9.66it/s]\n",
            "  4%|3         | 38/1000 [00:03<01:40,  9.59it/s]\n",
            "  4%|3         | 39/1000 [00:04<01:40,  9.54it/s]\n",
            "  4%|4         | 40/1000 [00:04<01:41,  9.47it/s]\n",
            "  4%|4         | 41/1000 [00:04<01:41,  9.45it/s]\n",
            "  4%|4         | 42/1000 [00:04<01:40,  9.49it/s]\n",
            "  4%|4         | 43/1000 [00:04<01:40,  9.49it/s]\n",
            "  4%|4         | 44/1000 [00:04<01:39,  9.56it/s]\n",
            "  5%|4         | 46/1000 [00:04<01:37,  9.83it/s]\n",
            "  5%|4         | 47/1000 [00:04<01:36,  9.84it/s]\n",
            "  5%|4         | 48/1000 [00:04<01:36,  9.86it/s]\n",
            "  5%|5         | 50/1000 [00:05<01:35,  9.97it/s]\n",
            "  5%|5         | 51/1000 [00:05<01:35,  9.91it/s]\n",
            "  5%|5         | 52/1000 [00:05<01:35,  9.93it/s]\n",
            "  5%|5         | 54/1000 [00:05<01:35,  9.89it/s]\n",
            "  6%|5         | 55/1000 [00:05<01:35,  9.87it/s]\n",
            "  6%|5         | 56/1000 [00:05<01:35,  9.88it/s]\n",
            "  6%|5         | 57/1000 [00:05<01:36,  9.77it/s]\n",
            "  6%|5         | 58/1000 [00:05<01:37,  9.64it/s]\n",
            "  6%|6         | 60/1000 [00:06<01:35,  9.84it/s]\n",
            "  6%|6         | 62/1000 [00:06<01:34,  9.96it/s]\n",
            "  6%|6         | 63/1000 [00:06<01:36,  9.70it/s]\n",
            "  6%|6         | 64/1000 [00:06<01:37,  9.63it/s]\n",
            "  6%|6         | 65/1000 [00:06<01:36,  9.70it/s]\n",
            "  7%|6         | 66/1000 [00:06<01:36,  9.67it/s]\n",
            "  7%|6         | 68/1000 [00:07<01:35,  9.71it/s]\n",
            "  7%|7         | 70/1000 [00:07<01:34,  9.80it/s]\n",
            "  7%|7         | 71/1000 [00:07<01:35,  9.74it/s]\n",
            "  7%|7         | 72/1000 [00:07<01:34,  9.79it/s]\n",
            "  7%|7         | 73/1000 [00:07<01:34,  9.77it/s]\n",
            "  7%|7         | 74/1000 [00:07<01:38,  9.44it/s]\n",
            "  8%|7         | 75/1000 [00:07<01:36,  9.55it/s]\n",
            "  8%|7         | 77/1000 [00:07<01:35,  9.69it/s]\n",
            "  8%|7         | 78/1000 [00:08<01:35,  9.66it/s]\n",
            "  8%|8         | 80/1000 [00:08<01:33,  9.79it/s]\n",
            "  8%|8         | 81/1000 [00:08<01:34,  9.75it/s]\n",
            "  8%|8         | 82/1000 [00:08<01:35,  9.58it/s]\n",
            "  8%|8         | 84/1000 [00:08<01:33,  9.80it/s]\n",
            "  8%|8         | 85/1000 [00:08<01:33,  9.81it/s]\n",
            "  9%|8         | 86/1000 [00:08<01:33,  9.81it/s]\n",
            "  9%|8         | 87/1000 [00:08<01:33,  9.79it/s]\n",
            "  9%|8         | 89/1000 [00:09<01:31,  9.97it/s]\n",
            "  9%|9         | 90/1000 [00:09<01:33,  9.72it/s]\n",
            "  9%|9         | 91/1000 [00:09<01:34,  9.66it/s]\n",
            "  9%|9         | 92/1000 [00:09<01:33,  9.72it/s]\n",
            "  9%|9         | 93/1000 [00:09<01:33,  9.69it/s]\n",
            " 10%|9         | 95/1000 [00:09<01:32,  9.77it/s]\n",
            " 10%|9         | 96/1000 [00:09<01:32,  9.73it/s]\n",
            " 10%|9         | 97/1000 [00:10<01:32,  9.71it/s]\n",
            " 10%|9         | 98/1000 [00:10<01:33,  9.61it/s]\n",
            " 10%|9         | 99/1000 [00:10<01:34,  9.55it/s]\n",
            " 10%|#         | 101/1000 [00:10<01:32,  9.67it/s]\n",
            " 10%|#         | 102/1000 [00:10<01:32,  9.70it/s]\n",
            " 10%|#         | 104/1000 [00:10<01:30,  9.90it/s]\n",
            " 10%|#         | 105/1000 [00:10<01:30,  9.84it/s]\n",
            " 11%|#         | 107/1000 [00:11<01:28, 10.04it/s]\n",
            " 11%|#         | 109/1000 [00:11<01:28, 10.02it/s]\n",
            " 11%|#1        | 110/1000 [00:11<01:30,  9.78it/s]\n",
            " 11%|#1        | 111/1000 [00:11<01:30,  9.81it/s]\n",
            " 11%|#1        | 112/1000 [00:11<01:30,  9.83it/s]\n",
            " 11%|#1        | 113/1000 [00:11<01:30,  9.85it/s]\n",
            " 11%|#1        | 114/1000 [00:11<01:30,  9.76it/s]\n",
            " 12%|#1        | 115/1000 [00:11<01:30,  9.73it/s]\n",
            " 12%|#1        | 116/1000 [00:11<01:31,  9.68it/s]\n",
            " 12%|#1        | 117/1000 [00:12<01:30,  9.74it/s]\n",
            " 12%|#1        | 118/1000 [00:12<01:30,  9.79it/s]\n",
            " 12%|#1        | 119/1000 [00:12<01:29,  9.80it/s]\n",
            " 12%|#2        | 120/1000 [00:12<01:29,  9.78it/s]\n",
            " 12%|#2        | 121/1000 [00:12<01:30,  9.67it/s]\n",
            " 12%|#2        | 122/1000 [00:12<01:30,  9.75it/s]\n",
            " 12%|#2        | 123/1000 [00:12<01:29,  9.76it/s]\n",
            " 12%|#2        | 125/1000 [00:12<01:29,  9.82it/s]\n",
            " 13%|#2        | 126/1000 [00:12<01:28,  9.82it/s]\n",
            " 13%|#2        | 127/1000 [00:13<01:29,  9.80it/s]\n",
            " 13%|#2        | 128/1000 [00:13<01:29,  9.72it/s]\n",
            " 13%|#2        | 129/1000 [00:13<01:30,  9.66it/s]\n",
            " 13%|#3        | 130/1000 [00:13<01:29,  9.72it/s]\n",
            " 13%|#3        | 131/1000 [00:13<01:29,  9.66it/s]\n",
            " 13%|#3        | 132/1000 [00:13<01:30,  9.62it/s]\n",
            " 13%|#3        | 134/1000 [00:13<01:28,  9.75it/s]\n",
            " 14%|#3        | 135/1000 [00:13<01:28,  9.80it/s]\n",
            " 14%|#3        | 136/1000 [00:13<01:28,  9.76it/s]\n",
            " 14%|#3        | 137/1000 [00:14<01:29,  9.67it/s]\n",
            " 14%|#3        | 138/1000 [00:14<01:29,  9.64it/s]\n",
            " 14%|#3        | 139/1000 [00:14<01:29,  9.66it/s]\n",
            " 14%|#4        | 140/1000 [00:14<01:29,  9.63it/s]\n",
            " 14%|#4        | 142/1000 [00:14<01:26,  9.94it/s]\n",
            " 14%|#4        | 143/1000 [00:14<01:27,  9.80it/s]\n",
            " 14%|#4        | 144/1000 [00:14<01:28,  9.71it/s]\n",
            " 14%|#4        | 145/1000 [00:14<01:28,  9.68it/s]\n",
            " 15%|#4        | 146/1000 [00:15<01:27,  9.76it/s]\n",
            " 15%|#4        | 147/1000 [00:15<01:27,  9.71it/s]\n",
            " 15%|#4        | 148/1000 [00:15<01:28,  9.67it/s]\n",
            " 15%|#4        | 149/1000 [00:15<01:28,  9.59it/s]\n",
            " 15%|#5        | 150/1000 [00:15<01:27,  9.67it/s]\n",
            " 15%|#5        | 152/1000 [00:15<01:26,  9.76it/s]\n",
            " 15%|#5        | 153/1000 [00:15<01:26,  9.75it/s]\n",
            " 15%|#5        | 154/1000 [00:15<01:26,  9.75it/s]\n",
            " 16%|#5        | 156/1000 [00:16<01:25,  9.89it/s]\n",
            " 16%|#5        | 157/1000 [00:16<01:26,  9.72it/s]\n",
            " 16%|#5        | 158/1000 [00:16<01:27,  9.60it/s]\n",
            " 16%|#5        | 159/1000 [00:16<01:27,  9.66it/s]\n",
            " 16%|#6        | 161/1000 [00:16<01:25,  9.76it/s]\n",
            " 16%|#6        | 163/1000 [00:16<01:25,  9.82it/s]\n",
            " 16%|#6        | 165/1000 [00:16<01:24,  9.89it/s]\n",
            " 17%|#6        | 166/1000 [00:17<01:24,  9.84it/s]\n",
            " 17%|#6        | 167/1000 [00:17<01:24,  9.87it/s]\n",
            " 17%|#6        | 168/1000 [00:17<01:24,  9.83it/s]\n",
            " 17%|#6        | 169/1000 [00:17<01:24,  9.84it/s]\n",
            " 17%|#7        | 170/1000 [00:17<01:24,  9.83it/s]\n",
            " 17%|#7        | 172/1000 [00:17<01:22,  9.98it/s]\n",
            " 17%|#7        | 173/1000 [00:17<01:24,  9.79it/s]\n",
            " 18%|#7        | 175/1000 [00:17<01:22,  9.97it/s]\n",
            " 18%|#7        | 176/1000 [00:18<01:22,  9.97it/s]\n",
            " 18%|#7        | 177/1000 [00:18<01:23,  9.84it/s]\n",
            " 18%|#7        | 178/1000 [00:18<01:31,  9.01it/s]\n",
            " 18%|#7        | 179/1000 [00:18<01:36,  8.51it/s]\n",
            " 18%|#8        | 180/1000 [00:18<01:32,  8.83it/s]\n",
            " 18%|#8        | 181/1000 [00:18<01:37,  8.39it/s]\n",
            " 18%|#8        | 182/1000 [00:18<01:35,  8.52it/s]\n",
            " 18%|#8        | 183/1000 [00:18<01:32,  8.80it/s]\n",
            " 18%|#8        | 184/1000 [00:19<01:32,  8.81it/s]\n",
            " 18%|#8        | 185/1000 [00:19<01:32,  8.83it/s]\n",
            " 19%|#8        | 186/1000 [00:19<01:36,  8.47it/s]\n",
            " 19%|#8        | 187/1000 [00:19<01:35,  8.48it/s]\n",
            " 19%|#8        | 188/1000 [00:19<01:33,  8.71it/s]\n",
            " 19%|#8        | 189/1000 [00:19<01:32,  8.74it/s]\n",
            " 19%|#9        | 190/1000 [00:19<01:30,  8.97it/s]\n",
            " 19%|#9        | 192/1000 [00:19<01:25,  9.43it/s]\n",
            " 19%|#9        | 193/1000 [00:20<01:25,  9.46it/s]\n",
            " 19%|#9        | 194/1000 [00:20<01:25,  9.39it/s]\n",
            " 20%|#9        | 195/1000 [00:20<01:25,  9.40it/s]\n",
            " 20%|#9        | 197/1000 [00:20<01:22,  9.77it/s]\n",
            " 20%|#9        | 198/1000 [00:20<01:21,  9.79it/s]\n",
            " 20%|#9        | 199/1000 [00:20<01:21,  9.83it/s]\n",
            " 20%|##        | 200/1000 [00:20<01:21,  9.78it/s]\n",
            " 20%|##        | 201/1000 [00:20<01:22,  9.74it/s]\n",
            " 20%|##        | 202/1000 [00:20<01:21,  9.74it/s]\n",
            " 20%|##        | 203/1000 [00:21<01:21,  9.77it/s]\n",
            " 20%|##        | 204/1000 [00:21<01:20,  9.83it/s]\n",
            " 21%|##        | 206/1000 [00:21<01:19, 10.03it/s]\n",
            " 21%|##        | 207/1000 [00:21<01:20,  9.84it/s]\n",
            " 21%|##        | 209/1000 [00:21<01:20,  9.87it/s]\n",
            " 21%|##1       | 210/1000 [00:21<01:19,  9.88it/s]\n",
            " 21%|##1       | 211/1000 [00:21<01:19,  9.89it/s]\n",
            " 21%|##1       | 212/1000 [00:21<01:20,  9.84it/s]\n",
            " 21%|##1       | 213/1000 [00:22<01:19,  9.87it/s]\n",
            " 21%|##1       | 214/1000 [00:22<01:21,  9.70it/s]\n",
            " 22%|##1       | 215/1000 [00:22<01:20,  9.69it/s]\n",
            " 22%|##1       | 216/1000 [00:22<01:21,  9.67it/s]\n",
            " 22%|##1       | 217/1000 [00:22<01:20,  9.75it/s]\n",
            " 22%|##1       | 218/1000 [00:22<01:20,  9.73it/s]\n",
            " 22%|##1       | 219/1000 [00:22<01:21,  9.61it/s]\n",
            " 22%|##2       | 220/1000 [00:22<01:21,  9.55it/s]\n",
            " 22%|##2       | 221/1000 [00:22<01:21,  9.53it/s]\n",
            " 22%|##2       | 222/1000 [00:22<01:21,  9.57it/s]\n",
            " 22%|##2       | 223/1000 [00:23<01:20,  9.60it/s]\n",
            " 22%|##2       | 225/1000 [00:23<01:18,  9.86it/s]\n",
            " 23%|##2       | 226/1000 [00:23<01:18,  9.87it/s]\n",
            " 23%|##2       | 227/1000 [00:23<01:18,  9.89it/s]\n",
            " 23%|##2       | 228/1000 [00:23<01:18,  9.89it/s]\n",
            " 23%|##2       | 229/1000 [00:23<01:18,  9.88it/s]\n",
            " 23%|##3       | 230/1000 [00:23<01:19,  9.73it/s]\n",
            " 23%|##3       | 231/1000 [00:23<01:18,  9.79it/s]\n",
            " 23%|##3       | 232/1000 [00:23<01:18,  9.79it/s]\n",
            " 23%|##3       | 233/1000 [00:24<01:21,  9.46it/s]\n",
            " 23%|##3       | 234/1000 [00:24<01:20,  9.46it/s]\n",
            " 24%|##3       | 236/1000 [00:24<01:18,  9.69it/s]\n",
            " 24%|##3       | 238/1000 [00:24<01:17,  9.86it/s]\n",
            " 24%|##3       | 239/1000 [00:24<01:17,  9.84it/s]\n",
            " 24%|##4       | 240/1000 [00:24<01:18,  9.73it/s]\n",
            " 24%|##4       | 242/1000 [00:25<01:17,  9.82it/s]\n",
            " 24%|##4       | 244/1000 [00:25<01:17,  9.80it/s]\n",
            " 24%|##4       | 245/1000 [00:25<01:17,  9.76it/s]\n",
            " 25%|##4       | 246/1000 [00:25<01:17,  9.76it/s]\n",
            " 25%|##4       | 248/1000 [00:25<01:15,  9.92it/s]\n",
            " 25%|##4       | 249/1000 [00:25<01:16,  9.87it/s]\n",
            " 25%|##5       | 250/1000 [00:25<01:16,  9.77it/s]\n",
            " 25%|##5       | 251/1000 [00:25<01:17,  9.73it/s]\n",
            " 25%|##5       | 252/1000 [00:26<01:17,  9.59it/s]\n",
            " 25%|##5       | 253/1000 [00:26<01:17,  9.58it/s]\n",
            " 25%|##5       | 254/1000 [00:26<01:18,  9.45it/s]\n",
            " 26%|##5       | 255/1000 [00:26<01:19,  9.39it/s]\n",
            " 26%|##5       | 257/1000 [00:26<01:17,  9.55it/s]\n",
            " 26%|##5       | 258/1000 [00:26<01:17,  9.54it/s]\n",
            " 26%|##5       | 259/1000 [00:26<01:18,  9.49it/s]\n",
            " 26%|##6       | 260/1000 [00:26<01:17,  9.59it/s]\n",
            " 26%|##6       | 262/1000 [00:27<01:14,  9.88it/s]\n",
            " 26%|##6       | 263/1000 [00:27<01:16,  9.64it/s]\n",
            " 26%|##6       | 264/1000 [00:27<01:16,  9.60it/s]\n",
            " 26%|##6       | 265/1000 [00:27<01:16,  9.55it/s]\n",
            " 27%|##6       | 266/1000 [00:27<01:16,  9.57it/s]\n",
            " 27%|##6       | 267/1000 [00:27<01:16,  9.54it/s]\n",
            " 27%|##6       | 268/1000 [00:27<01:16,  9.56it/s]\n",
            " 27%|##7       | 270/1000 [00:27<01:14,  9.74it/s]\n",
            " 27%|##7       | 271/1000 [00:28<01:15,  9.70it/s]\n",
            " 27%|##7       | 273/1000 [00:28<01:14,  9.82it/s]\n",
            " 27%|##7       | 274/1000 [00:28<01:14,  9.80it/s]\n",
            " 28%|##7       | 275/1000 [00:28<01:15,  9.62it/s]\n",
            " 28%|##7       | 276/1000 [00:28<01:15,  9.60it/s]\n",
            " 28%|##7       | 277/1000 [00:28<01:15,  9.54it/s]\n",
            " 28%|##7       | 278/1000 [00:28<01:15,  9.54it/s]\n",
            " 28%|##7       | 279/1000 [00:28<01:14,  9.62it/s]\n",
            " 28%|##8       | 281/1000 [00:29<01:14,  9.64it/s]\n",
            " 28%|##8       | 282/1000 [00:29<01:14,  9.64it/s]\n",
            " 28%|##8       | 283/1000 [00:29<01:14,  9.68it/s]\n",
            " 28%|##8       | 284/1000 [00:29<01:13,  9.71it/s]\n",
            " 28%|##8       | 285/1000 [00:29<01:13,  9.74it/s]\n",
            " 29%|##8       | 286/1000 [00:29<01:13,  9.72it/s]\n",
            " 29%|##8       | 287/1000 [00:29<01:13,  9.72it/s]\n",
            " 29%|##8       | 288/1000 [00:29<01:12,  9.79it/s]\n",
            " 29%|##8       | 289/1000 [00:29<01:12,  9.81it/s]\n",
            " 29%|##9       | 290/1000 [00:29<01:13,  9.66it/s]\n",
            " 29%|##9       | 291/1000 [00:30<01:13,  9.64it/s]\n",
            " 29%|##9       | 292/1000 [00:30<01:15,  9.36it/s]\n",
            " 29%|##9       | 293/1000 [00:30<01:14,  9.46it/s]\n",
            " 29%|##9       | 294/1000 [00:30<01:16,  9.24it/s]\n",
            " 30%|##9       | 295/1000 [00:30<01:15,  9.35it/s]\n",
            " 30%|##9       | 297/1000 [00:30<01:12,  9.63it/s]\n",
            " 30%|##9       | 298/1000 [00:30<01:22,  8.49it/s]\n",
            " 30%|##9       | 299/1000 [00:31<01:21,  8.63it/s]\n",
            " 30%|###       | 300/1000 [00:31<01:26,  8.12it/s]\n",
            " 30%|###       | 301/1000 [00:31<01:30,  7.75it/s]\n",
            " 30%|###       | 302/1000 [00:31<01:32,  7.52it/s]\n",
            " 30%|###       | 303/1000 [00:31<01:26,  8.04it/s]\n",
            " 30%|###       | 304/1000 [00:31<01:27,  7.97it/s]\n",
            " 30%|###       | 305/1000 [00:31<01:29,  7.78it/s]\n",
            " 31%|###       | 306/1000 [00:31<01:25,  8.14it/s]\n",
            " 31%|###       | 308/1000 [00:32<01:16,  9.01it/s]\n",
            " 31%|###       | 309/1000 [00:32<01:15,  9.15it/s]\n",
            " 31%|###1      | 310/1000 [00:32<01:14,  9.28it/s]\n",
            " 31%|###1      | 312/1000 [00:32<01:11,  9.66it/s]\n",
            " 31%|###1      | 313/1000 [00:32<01:12,  9.53it/s]\n",
            " 32%|###1      | 315/1000 [00:32<01:10,  9.77it/s]\n",
            " 32%|###1      | 317/1000 [00:33<01:10,  9.62it/s]\n",
            " 32%|###1      | 318/1000 [00:33<01:10,  9.66it/s]\n",
            " 32%|###1      | 319/1000 [00:33<01:11,  9.54it/s]\n",
            " 32%|###2      | 321/1000 [00:33<01:10,  9.67it/s]\n",
            " 32%|###2      | 322/1000 [00:33<01:10,  9.61it/s]\n",
            " 32%|###2      | 323/1000 [00:33<01:11,  9.50it/s]\n",
            " 32%|###2      | 324/1000 [00:33<01:10,  9.58it/s]\n",
            " 32%|###2      | 325/1000 [00:33<01:10,  9.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/50 [00:50<?, ?trial/s, best loss=?]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m/Users/keeks/GitHub/keekss/neural-network-numpy/model-and-tuning.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 71>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/keeks/GitHub/keekss/neural-network-numpy/model-and-tuning.ipynb#W6sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mdict\u001b[39m(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/keeks/GitHub/keekss/neural-network-numpy/model-and-tuning.ipynb#W6sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m         loss   \u001b[39m=\u001b[39m loss,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/keeks/GitHub/keekss/neural-network-numpy/model-and-tuning.ipynb#W6sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m         status \u001b[39m=\u001b[39m STATUS_OK\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/keeks/GitHub/keekss/neural-network-numpy/model-and-tuning.ipynb#W6sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m     )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/keeks/GitHub/keekss/neural-network-numpy/model-and-tuning.ipynb#W6sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m \u001b[39m# Optimize hyperparameters via loss function, search space,\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/keeks/GitHub/keekss/neural-network-numpy/model-and-tuning.ipynb#W6sZmlsZQ%3D%3D?line=69'>70</a>\u001b[0m \u001b[39m# and Tree Parzen Estimators, while saving summaries for each model\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/keeks/GitHub/keekss/neural-network-numpy/model-and-tuning.ipynb#W6sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m best \u001b[39m=\u001b[39m fmin(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/keeks/GitHub/keekss/neural-network-numpy/model-and-tuning.ipynb#W6sZmlsZQ%3D%3D?line=71'>72</a>\u001b[0m     fn        \u001b[39m=\u001b[39;49m objective,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/keeks/GitHub/keekss/neural-network-numpy/model-and-tuning.ipynb#W6sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m     space     \u001b[39m=\u001b[39;49m search_space,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/keeks/GitHub/keekss/neural-network-numpy/model-and-tuning.ipynb#W6sZmlsZQ%3D%3D?line=73'>74</a>\u001b[0m     algo      \u001b[39m=\u001b[39;49m tpe\u001b[39m.\u001b[39;49msuggest,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/keeks/GitHub/keekss/neural-network-numpy/model-and-tuning.ipynb#W6sZmlsZQ%3D%3D?line=74'>75</a>\u001b[0m     max_evals \u001b[39m=\u001b[39;49m \u001b[39m50\u001b[39;49m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/keeks/GitHub/keekss/neural-network-numpy/model-and-tuning.ipynb#W6sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m )\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/hyperopt/fmin.py:553\u001b[0m, in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    550\u001b[0m rval\u001b[39m.\u001b[39mcatch_eval_exceptions \u001b[39m=\u001b[39m catch_eval_exceptions\n\u001b[1;32m    552\u001b[0m \u001b[39m# next line is where the fmin is actually executed\u001b[39;00m\n\u001b[0;32m--> 553\u001b[0m rval\u001b[39m.\u001b[39;49mexhaust()\n\u001b[1;32m    555\u001b[0m \u001b[39mif\u001b[39;00m return_argmin:\n\u001b[1;32m    556\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(trials\u001b[39m.\u001b[39mtrials) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/hyperopt/fmin.py:356\u001b[0m, in \u001b[0;36mFMinIter.exhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mexhaust\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    355\u001b[0m     n_done \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials)\n\u001b[0;32m--> 356\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_evals \u001b[39m-\u001b[39;49m n_done, block_until_done\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49masynchronous)\n\u001b[1;32m    357\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials\u001b[39m.\u001b[39mrefresh()\n\u001b[1;32m    358\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/hyperopt/fmin.py:292\u001b[0m, in \u001b[0;36mFMinIter.run\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    289\u001b[0m     time\u001b[39m.\u001b[39msleep(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpoll_interval_secs)\n\u001b[1;32m    290\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    291\u001b[0m     \u001b[39m# -- loop over trials and do the jobs directly\u001b[39;00m\n\u001b[0;32m--> 292\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mserial_evaluate()\n\u001b[1;32m    294\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials\u001b[39m.\u001b[39mrefresh()\n\u001b[1;32m    295\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials_save_file \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m:\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/hyperopt/fmin.py:170\u001b[0m, in \u001b[0;36mFMinIter.serial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m    168\u001b[0m ctrl \u001b[39m=\u001b[39m base\u001b[39m.\u001b[39mCtrl(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials, current_trial\u001b[39m=\u001b[39mtrial)\n\u001b[1;32m    169\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 170\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdomain\u001b[39m.\u001b[39;49mevaluate(spec, ctrl)\n\u001b[1;32m    171\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    172\u001b[0m     logger\u001b[39m.\u001b[39merror(\u001b[39m\"\u001b[39m\u001b[39mjob exception: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m \u001b[39mstr\u001b[39m(e))\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/hyperopt/base.py:907\u001b[0m, in \u001b[0;36mDomain.evaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    899\u001b[0m     \u001b[39m# -- the \"work\" of evaluating `config` can be written\u001b[39;00m\n\u001b[1;32m    900\u001b[0m     \u001b[39m#    either into the pyll part (self.expr)\u001b[39;00m\n\u001b[1;32m    901\u001b[0m     \u001b[39m#    or the normal Python part (self.fn)\u001b[39;00m\n\u001b[1;32m    902\u001b[0m     pyll_rval \u001b[39m=\u001b[39m pyll\u001b[39m.\u001b[39mrec_eval(\n\u001b[1;32m    903\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexpr,\n\u001b[1;32m    904\u001b[0m         memo\u001b[39m=\u001b[39mmemo,\n\u001b[1;32m    905\u001b[0m         print_node_on_error\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrec_eval_print_node_on_error,\n\u001b[1;32m    906\u001b[0m     )\n\u001b[0;32m--> 907\u001b[0m     rval \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfn(pyll_rval)\n\u001b[1;32m    909\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(rval, (\u001b[39mfloat\u001b[39m, \u001b[39mint\u001b[39m, np\u001b[39m.\u001b[39mnumber)):\n\u001b[1;32m    910\u001b[0m     dict_rval \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mfloat\u001b[39m(rval), \u001b[39m\"\u001b[39m\u001b[39mstatus\u001b[39m\u001b[39m\"\u001b[39m: STATUS_OK}\n",
            "\u001b[1;32m/Users/keeks/GitHub/keekss/neural-network-numpy/model-and-tuning.ipynb Cell 7\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(search_space)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/keeks/GitHub/keekss/neural-network-numpy/model-and-tuning.ipynb#W6sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m recent_df \u001b[39m=\u001b[39m summaries_df \u001b[39mif\u001b[39;00m summaries_df\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m<\u001b[39m show_recent \\\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/keeks/GitHub/keekss/neural-network-numpy/model-and-tuning.ipynb#W6sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m     \u001b[39melse\u001b[39;00m summaries_df\u001b[39m.\u001b[39miloc[summaries_df\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\u001b[39m-\u001b[39mshow_recent:]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/keeks/GitHub/keekss/neural-network-numpy/model-and-tuning.ipynb#W6sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m \u001b[39m# Fit and return best loss value\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/keeks/GitHub/keekss/neural-network-numpy/model-and-tuning.ipynb#W6sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m loss \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/keeks/GitHub/keekss/neural-network-numpy/model-and-tuning.ipynb#W6sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m     X       \u001b[39m=\u001b[39;49m train_images,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/keeks/GitHub/keekss/neural-network-numpy/model-and-tuning.ipynb#W6sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m     y       \u001b[39m=\u001b[39;49m train_labels,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/keeks/GitHub/keekss/neural-network-numpy/model-and-tuning.ipynb#W6sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m     x_val   \u001b[39m=\u001b[39;49m test_images,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/keeks/GitHub/keekss/neural-network-numpy/model-and-tuning.ipynb#W6sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m     y_val   \u001b[39m=\u001b[39;49m test_labels,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/keeks/GitHub/keekss/neural-network-numpy/model-and-tuning.ipynb#W6sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m     \u001b[39m# By default, allow keep_rates_range to go up to 1\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/keeks/GitHub/keekss/neural-network-numpy/model-and-tuning.ipynb#W6sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m     keep_rates_range \u001b[39m=\u001b[39;49m [search_space[\u001b[39m'\u001b[39;49m\u001b[39mkeep_rates_min\u001b[39;49m\u001b[39m'\u001b[39;49m], \u001b[39m1\u001b[39;49m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/keeks/GitHub/keekss/neural-network-numpy/model-and-tuning.ipynb#W6sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m{\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/keeks/GitHub/keekss/neural-network-numpy/model-and-tuning.ipynb#W6sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m         key: search_space[key] \u001b[39mfor\u001b[39;49;00m key \u001b[39min\u001b[39;49;00m [\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/keeks/GitHub/keekss/neural-network-numpy/model-and-tuning.ipynb#W6sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m             \u001b[39m'\u001b[39;49m\u001b[39mbatch_size\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mkeep_rates_reshuffle\u001b[39;49m\u001b[39m'\u001b[39;49m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/keeks/GitHub/keekss/neural-network-numpy/model-and-tuning.ipynb#W6sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m         ]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/keeks/GitHub/keekss/neural-network-numpy/model-and-tuning.ipynb#W6sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m     },\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/keeks/GitHub/keekss/neural-network-numpy/model-and-tuning.ipynb#W6sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m     print_cache  \u001b[39m=\u001b[39;49m [\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/keeks/GitHub/keekss/neural-network-numpy/model-and-tuning.ipynb#W6sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m         \u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mBest \u001b[39;49m\u001b[39m{\u001b[39;49;00mshow_best\u001b[39m}\u001b[39;49;00m\u001b[39m models:\u001b[39;49m\u001b[39m'\u001b[39;49m,          best_df,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/keeks/GitHub/keekss/neural-network-numpy/model-and-tuning.ipynb#W6sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m         \u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mMost recent \u001b[39;49m\u001b[39m{\u001b[39;49;00mshow_recent\u001b[39m}\u001b[39;49;00m\u001b[39m models:\u001b[39;49m\u001b[39m'\u001b[39;49m, recent_df\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/keeks/GitHub/keekss/neural-network-numpy/model-and-tuning.ipynb#W6sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m     ]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/keeks/GitHub/keekss/neural-network-numpy/model-and-tuning.ipynb#W6sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/keeks/GitHub/keekss/neural-network-numpy/model-and-tuning.ipynb#W6sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/keeks/GitHub/keekss/neural-network-numpy/model-and-tuning.ipynb#W6sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mdict\u001b[39m(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/keeks/GitHub/keekss/neural-network-numpy/model-and-tuning.ipynb#W6sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m     loss   \u001b[39m=\u001b[39m loss,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/keeks/GitHub/keekss/neural-network-numpy/model-and-tuning.ipynb#W6sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m     status \u001b[39m=\u001b[39m STATUS_OK\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/keeks/GitHub/keekss/neural-network-numpy/model-and-tuning.ipynb#W6sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m )\n",
            "\u001b[1;32m/Users/keeks/GitHub/keekss/neural-network-numpy/model-and-tuning.ipynb Cell 7\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, x_val, y_val, lr, batch_size, keep_rates_manual, keep_rates_range, keep_rates_reshuffle, max_consec_strikes, max_strikes, max_epochs, verbose, print_cache, save_summary)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/keeks/GitHub/keekss/neural-network-numpy/model-and-tuning.ipynb#W6sZmlsZQ%3D%3D?line=78'>79</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepoch_index \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m max_epochs:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/keeks/GitHub/keekss/neural-network-numpy/model-and-tuning.ipynb#W6sZmlsZQ%3D%3D?line=79'>80</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepoch_index \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/keeks/GitHub/keekss/neural-network-numpy/model-and-tuning.ipynb#W6sZmlsZQ%3D%3D?line=81'>82</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_epoch(X, y, batch_size)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/keeks/GitHub/keekss/neural-network-numpy/model-and-tuning.ipynb#W6sZmlsZQ%3D%3D?line=82'>83</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39meval_epoch(X, y, x_val, y_val, start_time)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/keeks/GitHub/keekss/neural-network-numpy/model-and-tuning.ipynb#W6sZmlsZQ%3D%3D?line=84'>85</a>\u001b[0m     \u001b[39m# Access previous 2 losses and accuracies\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/keeks/GitHub/keekss/neural-network-numpy/model-and-tuning.ipynb#W6sZmlsZQ%3D%3D?line=85'>86</a>\u001b[0m     \u001b[39m# for validation data\u001b[39;00m\n",
            "\u001b[1;32m/Users/keeks/GitHub/keekss/neural-network-numpy/model-and-tuning.ipynb Cell 7\u001b[0m in \u001b[0;36mNeuralNetwork.train_epoch\u001b[0;34m(self, X, y, batch_size)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/keeks/GitHub/keekss/neural-network-numpy/model-and-tuning.ipynb#W6sZmlsZQ%3D%3D?line=182'>183</a>\u001b[0m \u001b[39miter\u001b[39m \u001b[39m=\u001b[39m tqdm(\u001b[39mzip\u001b[39m(batches_X, batches_y), total \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(batches_X)) \\\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/keeks/GitHub/keekss/neural-network-numpy/model-and-tuning.ipynb#W6sZmlsZQ%3D%3D?line=183'>184</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39melse\u001b[39;00m \u001b[39mzip\u001b[39m(batches_X, batches_y)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/keeks/GitHub/keekss/neural-network-numpy/model-and-tuning.ipynb#W6sZmlsZQ%3D%3D?line=184'>185</a>\u001b[0m \u001b[39mfor\u001b[39;00m b_X, b_y \u001b[39min\u001b[39;00m \u001b[39miter\u001b[39m:\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/keeks/GitHub/keekss/neural-network-numpy/model-and-tuning.ipynb#W6sZmlsZQ%3D%3D?line=185'>186</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_mini_batch(b_X, b_y)\n",
            "\u001b[1;32m/Users/keeks/GitHub/keekss/neural-network-numpy/model-and-tuning.ipynb Cell 7\u001b[0m in \u001b[0;36mNeuralNetwork.train_mini_batch\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/keeks/GitHub/keekss/neural-network-numpy/model-and-tuning.ipynb#W6sZmlsZQ%3D%3D?line=165'>166</a>\u001b[0m \u001b[39m# Update weights\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/keeks/GitHub/keekss/neural-network-numpy/model-and-tuning.ipynb#W6sZmlsZQ%3D%3D?line=166'>167</a>\u001b[0m step \u001b[39m=\u001b[39m lr \u001b[39m*\u001b[39m m_hat \u001b[39m/\u001b[39m (np\u001b[39m.\u001b[39msqrt(v_hat) \u001b[39m+\u001b[39m epsl)\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/keeks/GitHub/keekss/neural-network-numpy/model-and-tuning.ipynb#W6sZmlsZQ%3D%3D?line=167'>168</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights[i] \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m step\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/keeks/GitHub/keekss/neural-network-numpy/model-and-tuning.ipynb#W6sZmlsZQ%3D%3D?line=168'>169</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madam_t \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "def initialize_model(search_space):\n",
        "    \"\"\"Initialize the neural network model with the given hyperparameters.\"\"\"\n",
        "    return NeuralNetwork(\n",
        "        inputs=train_images.shape[1],\n",
        "        outputs=train_labels.shape[1],\n",
        "        **{\n",
        "            key: search_space[key] for key in [\n",
        "                'h_layers', 'shape', 'max_height', 'shrink_factor',\n",
        "            ]\n",
        "        }   \n",
        "    )\n",
        "\n",
        "def get_best_and_recent(summaries_df, show_best=5, show_recent=5):\n",
        "    \"\"\"Get the best and most recent models from the summaries dataframe.\"\"\"\n",
        "    best_df = summaries_df.sort_values('min_loss_val')\n",
        "    best_df = best_df if summaries_df.shape[0] < show_best else best_df.iloc[:show_best]\n",
        "    recent_df = summaries_df if summaries_df.shape[0] < show_recent else summaries_df.iloc[-show_recent:]\n",
        "    return best_df, recent_df\n",
        "\n",
        "def objective(search_space):\n",
        "    \"\"\"The objective function for hyperopt.\"\"\"\n",
        "    model = initialize_model(search_space)\n",
        "    summaries_df = pd.read_csv('summaries.csv', index_col=0)\n",
        "    best_df, recent_df = get_best_and_recent(summaries_df)\n",
        "    try:\n",
        "        loss = model.fit(\n",
        "            X=train_images,\n",
        "            y=train_labels,\n",
        "            x_val=test_images,\n",
        "            y_val=test_labels,\n",
        "            keep_rates_range=[search_space['keep_rates_min'], 1],\n",
        "            **{\n",
        "                key: search_space[key] for key in [\n",
        "                    'batch_size', 'lr', 'keep_rates_reshuffle'\n",
        "                ]\n",
        "            },\n",
        "            print_cache=[\n",
        "                f'Best {show_best} models:', best_df,\n",
        "                f'Most recent {show_recent} models:', recent_df\n",
        "            ]\n",
        "        )\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to fit model: {e}\")\n",
        "        loss = float('inf')\n",
        "    return dict(\n",
        "        loss=loss,\n",
        "        status=STATUS_OK\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Notes from hyperparameter tuning\n",
        "\n",
        "Though hyperparameter trials and logging to `summaries.csv`, certain ranges for certain hyperparameters have generally led to lowest validation loss.\n",
        "\n",
        "These ranges have been updated for subsequent calls to `hyperopt.fmin`, with expansion of thus-far unexplored ranges if the optimal ranges have tended toward either edge of the current ranges.\n",
        "\n",
        "Hyperparameter | Min | Max\n",
        ":-- | --: | --: \n",
        "`h_layers` | `1` | `4`\n",
        "`keep_rates_min` | `0.92` | `1`\n",
        "`lr` | `3e-4` | `9e-4`\n",
        "`batch_size` | `500` | `4000`\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "HW4_Neural_Network.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "2333e419b2f07a60c2ae60e8997d53db9e1d7ffb1f994aec011150308f05aebd"
    },
    "kernelspec": {
      "display_name": "Python 3.8.13 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
